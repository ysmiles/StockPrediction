{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# print(pd.__version__)\n",
    "\n",
    "def loaddata(filename='train.csv', ratio=0.05):\n",
    "    data = pd.read_csv('data/' + filename, index_col=0, nrows=int(ratio * 40000))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>Feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Ret_175</th>\n",
       "      <th>Ret_176</th>\n",
       "      <th>Ret_177</th>\n",
       "      <th>Ret_178</th>\n",
       "      <th>Ret_179</th>\n",
       "      <th>Ret_180</th>\n",
       "      <th>Ret_PlusOne</th>\n",
       "      <th>Ret_PlusTwo</th>\n",
       "      <th>Weight_Intraday</th>\n",
       "      <th>Weight_Daily</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75751</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002688</td>\n",
       "      <td>2.246448e-03</td>\n",
       "      <td>-8.384789e-04</td>\n",
       "      <td>-6.953224e-04</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.001974</td>\n",
       "      <td>-0.019512</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>1.251508e+06</td>\n",
       "      <td>1.564385e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.388896</td>\n",
       "      <td>17369</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>1.231983e-04</td>\n",
       "      <td>2.479729e-04</td>\n",
       "      <td>3.315418e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.002939</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>1.733950e+06</td>\n",
       "      <td>2.167438e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.696727</td>\n",
       "      <td>0.739591</td>\n",
       "      <td>-0.167928</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.471947</td>\n",
       "      <td>8277</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000524</td>\n",
       "      <td>-3.942209e-04</td>\n",
       "      <td>1.162100e-04</td>\n",
       "      <td>5.322557e-04</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>-0.024791</td>\n",
       "      <td>0.015711</td>\n",
       "      <td>1.529197e+06</td>\n",
       "      <td>1.911497e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.694350</td>\n",
       "      <td>1.568248</td>\n",
       "      <td>0.479073</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.120653</td>\n",
       "      <td>22508</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>-8.969682e-05</td>\n",
       "      <td>2.883115e-04</td>\n",
       "      <td>-1.281102e-04</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.005680</td>\n",
       "      <td>-0.002190</td>\n",
       "      <td>1.711569e+06</td>\n",
       "      <td>2.139462e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.736489</td>\n",
       "      <td>2.765531</td>\n",
       "      <td>1.245280</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.866985</td>\n",
       "      <td>22423</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>2.723557e-05</td>\n",
       "      <td>2.449409e-03</td>\n",
       "      <td>8.619882e-06</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.036104</td>\n",
       "      <td>-0.026552</td>\n",
       "      <td>1.267270e+06</td>\n",
       "      <td>1.584088e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.680515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.227034</td>\n",
       "      <td>24099</td>\n",
       "      <td>0.2064</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>1.411510e-03</td>\n",
       "      <td>1.879851e-03</td>\n",
       "      <td>-9.458593e-04</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.031098</td>\n",
       "      <td>-0.006551</td>\n",
       "      <td>1.431110e+06</td>\n",
       "      <td>1.788888e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.230636</td>\n",
       "      <td>-0.227021</td>\n",
       "      <td>-0.084126</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.095007</td>\n",
       "      <td>39351</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>-4.080826e-04</td>\n",
       "      <td>8.559887e-05</td>\n",
       "      <td>-1.192267e-05</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>-0.011105</td>\n",
       "      <td>-0.030745</td>\n",
       "      <td>1.719166e+06</td>\n",
       "      <td>2.148958e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.582955</td>\n",
       "      <td>0.157344</td>\n",
       "      <td>0.617261</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.177333</td>\n",
       "      <td>92214</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>-2.496958e-04</td>\n",
       "      <td>9.815168e-06</td>\n",
       "      <td>1.620296e-05</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.020268</td>\n",
       "      <td>-0.059093</td>\n",
       "      <td>1.349917e+06</td>\n",
       "      <td>1.687396e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.187950</td>\n",
       "      <td>-0.259820</td>\n",
       "      <td>0.047637</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.381621</td>\n",
       "      <td>18418</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-1.675738e-05</td>\n",
       "      <td>-6.565766e-06</td>\n",
       "      <td>-3.834451e-04</td>\n",
       "      <td>-0.000929</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>-0.009348</td>\n",
       "      <td>-0.024755</td>\n",
       "      <td>1.536680e+06</td>\n",
       "      <td>1.920849e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.883570</td>\n",
       "      <td>0.813783</td>\n",
       "      <td>0.796746</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.021982</td>\n",
       "      <td>47637</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002510</td>\n",
       "      <td>6.401681e-04</td>\n",
       "      <td>6.231028e-04</td>\n",
       "      <td>6.077426e-04</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-0.000597</td>\n",
       "      <td>0.022407</td>\n",
       "      <td>-0.010674</td>\n",
       "      <td>1.370804e+06</td>\n",
       "      <td>1.713505e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.226944</td>\n",
       "      <td>0.442309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>51499</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>-1.110030e-03</td>\n",
       "      <td>1.739014e-04</td>\n",
       "      <td>1.207965e-05</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.013504</td>\n",
       "      <td>1.525034e+06</td>\n",
       "      <td>1.906293e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.144114</td>\n",
       "      <td>-0.731070</td>\n",
       "      <td>-0.682722</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.668712</td>\n",
       "      <td>79888</td>\n",
       "      <td>0.2109</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-6.732017e-04</td>\n",
       "      <td>2.040139e-03</td>\n",
       "      <td>-7.816066e-06</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>-0.000356</td>\n",
       "      <td>0.097741</td>\n",
       "      <td>0.035604</td>\n",
       "      <td>1.529522e+06</td>\n",
       "      <td>1.911903e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.041236</td>\n",
       "      <td>-0.386044</td>\n",
       "      <td>0.255167</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.035637</td>\n",
       "      <td>63267</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>5.338005e-06</td>\n",
       "      <td>-3.320290e-04</td>\n",
       "      <td>1.663772e-04</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>-0.027103</td>\n",
       "      <td>1.813731e+06</td>\n",
       "      <td>2.267164e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.480362</td>\n",
       "      <td>0.915407</td>\n",
       "      <td>1.381156</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.223401</td>\n",
       "      <td>35023</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-1.857928e-03</td>\n",
       "      <td>1.133055e-03</td>\n",
       "      <td>-1.288622e-03</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.000574</td>\n",
       "      <td>-0.010936</td>\n",
       "      <td>-0.019700</td>\n",
       "      <td>1.460081e+06</td>\n",
       "      <td>1.825101e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.103217</td>\n",
       "      <td>0.581729</td>\n",
       "      <td>0.290436</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.046317</td>\n",
       "      <td>76131</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>-5.690433e-04</td>\n",
       "      <td>-1.880131e-04</td>\n",
       "      <td>-8.045307e-06</td>\n",
       "      <td>-0.000771</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>-0.001756</td>\n",
       "      <td>1.555965e+06</td>\n",
       "      <td>1.944956e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152788</td>\n",
       "      <td>0.465036</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.611268</td>\n",
       "      <td>69564</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-1.566804e-04</td>\n",
       "      <td>1.592441e-04</td>\n",
       "      <td>1.500476e-04</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>-0.016166</td>\n",
       "      <td>1.423454e+06</td>\n",
       "      <td>1.779318e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.366156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.697484</td>\n",
       "      <td>94022</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000388</td>\n",
       "      <td>1.393200e-04</td>\n",
       "      <td>-1.439964e-04</td>\n",
       "      <td>6.674850e-04</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>-0.003522</td>\n",
       "      <td>1.861237e+06</td>\n",
       "      <td>2.326546e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.650709</td>\n",
       "      <td>2.317553</td>\n",
       "      <td>1.305126</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.066674</td>\n",
       "      <td>16080</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001031</td>\n",
       "      <td>1.033490e-04</td>\n",
       "      <td>-7.209001e-04</td>\n",
       "      <td>-4.000919e-04</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.010067</td>\n",
       "      <td>-0.006406</td>\n",
       "      <td>1.436242e+06</td>\n",
       "      <td>1.795303e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.015527</td>\n",
       "      <td>-0.044450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.072971</td>\n",
       "      <td>14259</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000869</td>\n",
       "      <td>6.581058e-04</td>\n",
       "      <td>2.950673e-06</td>\n",
       "      <td>3.020044e-03</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>-0.000638</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>-0.007578</td>\n",
       "      <td>1.675006e+06</td>\n",
       "      <td>2.093757e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.225009</td>\n",
       "      <td>0.787305</td>\n",
       "      <td>0.642112</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.064140</td>\n",
       "      <td>65146</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>-2.195779e-04</td>\n",
       "      <td>5.612446e-04</td>\n",
       "      <td>5.640549e-04</td>\n",
       "      <td>-0.000682</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>1.695051e+06</td>\n",
       "      <td>2.118814e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.394518</td>\n",
       "      <td>0.155395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.190561</td>\n",
       "      <td>47683</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.614084e-04</td>\n",
       "      <td>1.255061e-03</td>\n",
       "      <td>-1.009536e-03</td>\n",
       "      <td>-0.001264</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>1.511918e+06</td>\n",
       "      <td>1.889897e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.396875</td>\n",
       "      <td>0.341218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.117522</td>\n",
       "      <td>35266</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-1.831635e-03</td>\n",
       "      <td>-4.656236e-04</td>\n",
       "      <td>-8.925414e-04</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>-0.023468</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>1.450708e+06</td>\n",
       "      <td>1.813385e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.812319</td>\n",
       "      <td>49660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>2.559671e-04</td>\n",
       "      <td>-1.547616e-05</td>\n",
       "      <td>2.179806e-04</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>1.501551e+06</td>\n",
       "      <td>1.876939e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.833909</td>\n",
       "      <td>0.807421</td>\n",
       "      <td>0.396305</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.225614</td>\n",
       "      <td>57773</td>\n",
       "      <td>0.2986</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>-3.362421e-03</td>\n",
       "      <td>-2.675504e-03</td>\n",
       "      <td>2.674716e-03</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>-0.003376</td>\n",
       "      <td>0.076162</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>1.208516e+06</td>\n",
       "      <td>1.510645e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.975182</td>\n",
       "      <td>0.924188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.981710</td>\n",
       "      <td>34161</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>5.590299e-04</td>\n",
       "      <td>5.731391e-04</td>\n",
       "      <td>1.153140e-03</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>-0.005204</td>\n",
       "      <td>0.014411</td>\n",
       "      <td>1.778732e+06</td>\n",
       "      <td>2.223415e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.455055</td>\n",
       "      <td>-0.754385</td>\n",
       "      <td>-0.267288</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.069727</td>\n",
       "      <td>64351</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>-5.948549e-04</td>\n",
       "      <td>-3.920858e-04</td>\n",
       "      <td>-9.911355e-05</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>1.513133e+06</td>\n",
       "      <td>1.891416e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.943837</td>\n",
       "      <td>-0.308297</td>\n",
       "      <td>-0.597960</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>19660</td>\n",
       "      <td>0.2323</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>-3.296061e-04</td>\n",
       "      <td>-9.017426e-04</td>\n",
       "      <td>-3.611286e-04</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.032365</td>\n",
       "      <td>-0.017119</td>\n",
       "      <td>1.557176e+06</td>\n",
       "      <td>1.946470e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745994</td>\n",
       "      <td>-0.479567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310152</td>\n",
       "      <td>94975</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008361</td>\n",
       "      <td>-7.114985e-03</td>\n",
       "      <td>1.186144e-03</td>\n",
       "      <td>-7.075140e-03</td>\n",
       "      <td>-0.005854</td>\n",
       "      <td>-0.003510</td>\n",
       "      <td>0.129496</td>\n",
       "      <td>-0.012954</td>\n",
       "      <td>1.340404e+06</td>\n",
       "      <td>1.675506e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.128934</td>\n",
       "      <td>-0.297645</td>\n",
       "      <td>-0.353155</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.053215</td>\n",
       "      <td>99483</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>-8.797364e-04</td>\n",
       "      <td>6.278138e-04</td>\n",
       "      <td>-7.483020e-04</td>\n",
       "      <td>-0.000504</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>-0.007302</td>\n",
       "      <td>1.344794e+06</td>\n",
       "      <td>1.680992e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.393162</td>\n",
       "      <td>0.184165</td>\n",
       "      <td>0.399026</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.007371</td>\n",
       "      <td>40712</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>-1.157849e-05</td>\n",
       "      <td>-1.215498e-06</td>\n",
       "      <td>5.866008e-05</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.023321</td>\n",
       "      <td>-0.002465</td>\n",
       "      <td>1.895309e+06</td>\n",
       "      <td>2.369136e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.546610</td>\n",
       "      <td>-1.332731</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.205426</td>\n",
       "      <td>82574</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>3.577820e-04</td>\n",
       "      <td>-3.596965e-04</td>\n",
       "      <td>7.129191e-04</td>\n",
       "      <td>-0.002467</td>\n",
       "      <td>-0.000701</td>\n",
       "      <td>-0.003744</td>\n",
       "      <td>-0.021519</td>\n",
       "      <td>1.369248e+06</td>\n",
       "      <td>1.711560e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.468160</td>\n",
       "      <td>-0.305419</td>\n",
       "      <td>-0.043498</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95570</td>\n",
       "      <td>0.2064</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>5.791017e-06</td>\n",
       "      <td>9.837415e-04</td>\n",
       "      <td>6.363922e-04</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.022971</td>\n",
       "      <td>0.030974</td>\n",
       "      <td>1.256701e+06</td>\n",
       "      <td>1.570876e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.739120</td>\n",
       "      <td>0.275225</td>\n",
       "      <td>0.697625</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.074886</td>\n",
       "      <td>94258</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>2.857951e-04</td>\n",
       "      <td>-1.697916e-07</td>\n",
       "      <td>2.008845e-05</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>-0.010891</td>\n",
       "      <td>-0.004293</td>\n",
       "      <td>1.890853e+06</td>\n",
       "      <td>2.363567e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.040592</td>\n",
       "      <td>-0.118391</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.117050</td>\n",
       "      <td>5453</td>\n",
       "      <td>0.2064</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.850987e-04</td>\n",
       "      <td>8.670662e-04</td>\n",
       "      <td>1.459405e-03</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.015722</td>\n",
       "      <td>-0.013927</td>\n",
       "      <td>1.490222e+06</td>\n",
       "      <td>1.862777e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.124996</td>\n",
       "      <td>0.095273</td>\n",
       "      <td>0.242200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.023881</td>\n",
       "      <td>29262</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>-3.943045e-06</td>\n",
       "      <td>5.623422e-04</td>\n",
       "      <td>5.668099e-04</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>-0.014878</td>\n",
       "      <td>-0.034630</td>\n",
       "      <td>1.272266e+06</td>\n",
       "      <td>1.590332e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023079</td>\n",
       "      <td>-0.976493</td>\n",
       "      <td>-0.870644</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.451283</td>\n",
       "      <td>80829</td>\n",
       "      <td>0.2064</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>1.276656e-04</td>\n",
       "      <td>1.023693e-03</td>\n",
       "      <td>1.339725e-04</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.012572</td>\n",
       "      <td>-0.054967</td>\n",
       "      <td>1.198448e+06</td>\n",
       "      <td>1.498059e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.196171</td>\n",
       "      <td>-0.578981</td>\n",
       "      <td>-0.203562</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.673126</td>\n",
       "      <td>61797</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-6.818950e-06</td>\n",
       "      <td>1.184736e-05</td>\n",
       "      <td>-9.196969e-04</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.017264</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>1.623057e+06</td>\n",
       "      <td>2.028821e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.645218</td>\n",
       "      <td>0.354109</td>\n",
       "      <td>-0.104157</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.344572</td>\n",
       "      <td>45523</td>\n",
       "      <td>0.2986</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>-4.791143e-04</td>\n",
       "      <td>9.550447e-04</td>\n",
       "      <td>1.059973e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000484</td>\n",
       "      <td>-0.041075</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>1.309402e+06</td>\n",
       "      <td>1.636753e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.203171</td>\n",
       "      <td>0.226622</td>\n",
       "      <td>0.332481</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.022872</td>\n",
       "      <td>82781</td>\n",
       "      <td>0.2064</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>1.146207e-06</td>\n",
       "      <td>4.923621e-04</td>\n",
       "      <td>-2.438922e-04</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>-0.004663</td>\n",
       "      <td>1.755921e+06</td>\n",
       "      <td>2.194901e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.076217</td>\n",
       "      <td>0.940583</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.261668</td>\n",
       "      <td>67692</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-3.340021e-04</td>\n",
       "      <td>2.279709e-04</td>\n",
       "      <td>2.336519e-04</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.007115</td>\n",
       "      <td>-0.002349</td>\n",
       "      <td>1.411992e+06</td>\n",
       "      <td>1.764990e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.106057</td>\n",
       "      <td>84947</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000268</td>\n",
       "      <td>-4.550989e-06</td>\n",
       "      <td>-1.312794e-04</td>\n",
       "      <td>3.241671e-06</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.010295</td>\n",
       "      <td>-0.053464</td>\n",
       "      <td>1.622031e+06</td>\n",
       "      <td>2.027539e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.152784</td>\n",
       "      <td>0.232670</td>\n",
       "      <td>0.331534</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.273723</td>\n",
       "      <td>54939</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-1.902923e-04</td>\n",
       "      <td>1.432672e-03</td>\n",
       "      <td>-1.692896e-04</td>\n",
       "      <td>-0.000888</td>\n",
       "      <td>-0.000721</td>\n",
       "      <td>-0.009063</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>1.679530e+06</td>\n",
       "      <td>2.099413e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.995871</td>\n",
       "      <td>1.157415</td>\n",
       "      <td>1.234015</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>8277</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>-2.058026e-04</td>\n",
       "      <td>5.725216e-06</td>\n",
       "      <td>-4.422490e-04</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.010205</td>\n",
       "      <td>-0.003287</td>\n",
       "      <td>1.580700e+06</td>\n",
       "      <td>1.975874e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.618986</td>\n",
       "      <td>-0.029308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.430384</td>\n",
       "      <td>48389</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>1.027195e-04</td>\n",
       "      <td>-2.549077e-05</td>\n",
       "      <td>8.745209e-05</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>-0.002402</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>1.802324e+06</td>\n",
       "      <td>2.252905e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.555872</td>\n",
       "      <td>0.028952</td>\n",
       "      <td>-0.166529</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.201376</td>\n",
       "      <td>51499</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.286784e-04</td>\n",
       "      <td>-1.658063e-03</td>\n",
       "      <td>-6.814984e-06</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>-0.010317</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>1.469613e+06</td>\n",
       "      <td>1.837016e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.888821</td>\n",
       "      <td>2.102174</td>\n",
       "      <td>0.546921</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.499608</td>\n",
       "      <td>76464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>6.717882e-04</td>\n",
       "      <td>9.956740e-04</td>\n",
       "      <td>-2.771507e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>-0.011328</td>\n",
       "      <td>-0.003870</td>\n",
       "      <td>1.279307e+06</td>\n",
       "      <td>1.599133e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.710776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.254801</td>\n",
       "      <td>87553</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-2.173213e-07</td>\n",
       "      <td>-3.025734e-04</td>\n",
       "      <td>-3.073193e-04</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>-0.000593</td>\n",
       "      <td>-0.017155</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>1.728225e+06</td>\n",
       "      <td>2.160282e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.512331</td>\n",
       "      <td>0.664232</td>\n",
       "      <td>0.980403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.119552</td>\n",
       "      <td>56524</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>2.492693e-04</td>\n",
       "      <td>-4.323564e-06</td>\n",
       "      <td>-4.955796e-06</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.015996</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>1.875855e+06</td>\n",
       "      <td>2.344819e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.682440</td>\n",
       "      <td>3.396569</td>\n",
       "      <td>0.820769</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.734343</td>\n",
       "      <td>48481</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>7.844714e-05</td>\n",
       "      <td>-5.023798e-04</td>\n",
       "      <td>1.572674e-07</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>-0.027150</td>\n",
       "      <td>0.015245</td>\n",
       "      <td>1.514668e+06</td>\n",
       "      <td>1.893334e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.941491</td>\n",
       "      <td>0.668330</td>\n",
       "      <td>1.033846</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.253918</td>\n",
       "      <td>12347</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.403474e-05</td>\n",
       "      <td>9.455745e-06</td>\n",
       "      <td>-1.323697e-05</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>-0.010499</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>1.949350e+06</td>\n",
       "      <td>2.436687e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.636452</td>\n",
       "      <td>50271</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-2.637521e-04</td>\n",
       "      <td>-8.320440e-04</td>\n",
       "      <td>8.221117e-04</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>1.424179e+06</td>\n",
       "      <td>1.780223e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.045789</td>\n",
       "      <td>-0.457681</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.678332</td>\n",
       "      <td>5170</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>-2.196378e-03</td>\n",
       "      <td>-1.474602e-03</td>\n",
       "      <td>-5.412621e-06</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.011625</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>1.252724e+06</td>\n",
       "      <td>1.565906e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.961538</td>\n",
       "      <td>1.639694</td>\n",
       "      <td>1.571560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.911557</td>\n",
       "      <td>1344</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-8.472979e-06</td>\n",
       "      <td>-9.385212e-06</td>\n",
       "      <td>-2.563526e-04</td>\n",
       "      <td>-0.000487</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>1.644097e+06</td>\n",
       "      <td>2.055121e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.198985</td>\n",
       "      <td>0.327814</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58773</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>2.335623e-04</td>\n",
       "      <td>-9.486519e-04</td>\n",
       "      <td>-5.435486e-06</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.001219</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>-0.009084</td>\n",
       "      <td>1.589009e+06</td>\n",
       "      <td>1.986261e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.647647</td>\n",
       "      <td>-0.477716</td>\n",
       "      <td>-0.258534</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.514951</td>\n",
       "      <td>24150</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>8.350968e-04</td>\n",
       "      <td>2.820332e-04</td>\n",
       "      <td>-5.750897e-04</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>-0.021563</td>\n",
       "      <td>0.024478</td>\n",
       "      <td>1.251844e+06</td>\n",
       "      <td>1.564805e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.453848</td>\n",
       "      <td>0.665826</td>\n",
       "      <td>0.972017</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.151838</td>\n",
       "      <td>14937</td>\n",
       "      <td>0.2986</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000615</td>\n",
       "      <td>-4.085132e-04</td>\n",
       "      <td>-1.158836e-04</td>\n",
       "      <td>2.958219e-04</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>-0.018140</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>1.479917e+06</td>\n",
       "      <td>1.849896e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.163506</td>\n",
       "      <td>-0.608649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.039211</td>\n",
       "      <td>56348</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>1.038278e-03</td>\n",
       "      <td>6.981343e-04</td>\n",
       "      <td>6.778698e-06</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.019756</td>\n",
       "      <td>-0.010661</td>\n",
       "      <td>1.550242e+06</td>\n",
       "      <td>1.937802e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.006582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.190597</td>\n",
       "      <td>98649</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>-3.580614e-03</td>\n",
       "      <td>-2.188811e-03</td>\n",
       "      <td>-5.757392e-03</td>\n",
       "      <td>-0.004077</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>-0.030099</td>\n",
       "      <td>0.027257</td>\n",
       "      <td>1.439026e+06</td>\n",
       "      <td>1.798783e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074628</td>\n",
       "      <td>-0.776328</td>\n",
       "      <td>-0.350850</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.498919</td>\n",
       "      <td>27376</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.967419e-06</td>\n",
       "      <td>1.029781e-03</td>\n",
       "      <td>-1.024820e-03</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>-0.016628</td>\n",
       "      <td>1.639155e+06</td>\n",
       "      <td>2.048944e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.129617</td>\n",
       "      <td>0.079880</td>\n",
       "      <td>-0.198706</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.299925</td>\n",
       "      <td>22886</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>-1.687280e-03</td>\n",
       "      <td>1.249581e-06</td>\n",
       "      <td>-9.508965e-06</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.029227</td>\n",
       "      <td>0.045893</td>\n",
       "      <td>1.256048e+06</td>\n",
       "      <td>1.570060e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "Id                                                                       \n",
       "1           NaN        NaN        NaN        NaN        8.0        NaN   \n",
       "2           NaN        NaN        NaN        NaN        3.0   0.388896   \n",
       "3           NaN  -0.696727   0.739591  -0.167928        9.0   0.471947   \n",
       "4           NaN  -0.694350   1.568248   0.479073        5.0   0.120653   \n",
       "5           6.0  -1.736489   2.765531   1.245280        7.0   4.866985   \n",
       "6           NaN        NaN  -0.680515        NaN        1.0   0.227034   \n",
       "7           NaN  -0.230636  -0.227021  -0.084126        7.0  -0.095007   \n",
       "8           NaN   2.582955   0.157344   0.617261        8.0  -0.177333   \n",
       "9           NaN  -0.187950  -0.259820   0.047637        8.0  -0.381621   \n",
       "10          NaN   2.883570   0.813783   0.796746        7.0   0.021982   \n",
       "11          NaN   2.226944   0.442309        NaN        1.0   0.009146   \n",
       "12          NaN   2.144114  -0.731070  -0.682722        8.0  -0.668712   \n",
       "13          6.0   0.041236  -0.386044   0.255167        5.0  -0.035637   \n",
       "14          NaN   0.480362   0.915407   1.381156        7.0   0.223401   \n",
       "15          NaN  -0.103217   0.581729   0.290436        7.0   0.046317   \n",
       "16          NaN        NaN   0.152788   0.465036        7.0  -0.611268   \n",
       "17          NaN        NaN  -0.366156        NaN        1.0   0.697484   \n",
       "18          8.0  -1.650709   2.317553   1.305126        8.0   1.066674   \n",
       "19          NaN  -0.015527  -0.044450        NaN        3.0   0.072971   \n",
       "20          8.0  -1.225009   0.787305   0.642112        5.0   0.064140   \n",
       "21          2.0  -0.394518   0.155395        NaN        5.0   0.190561   \n",
       "22          NaN  -1.396875   0.341218        NaN        1.0   0.117522   \n",
       "23          NaN        NaN   0.515582        NaN        1.0   3.812319   \n",
       "24          NaN  -1.833909   0.807421   0.396305        7.0   0.225614   \n",
       "25          7.0  -0.975182   0.924188        NaN        3.0   0.981710   \n",
       "26          NaN   0.455055  -0.754385  -0.267288        8.0  -0.069727   \n",
       "27         10.0   0.943837  -0.308297  -0.597960        5.0   0.091429   \n",
       "28          NaN   0.745994  -0.479567        NaN        1.0   0.310152   \n",
       "29          NaN   1.128934  -0.297645  -0.353155        9.0   0.053215   \n",
       "30          NaN  -1.393162   0.184165   0.399026        2.0  -0.007371   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1971        1.0        NaN  -0.546610  -1.332731        9.0  -0.205426   \n",
       "1972        NaN   0.468160  -0.305419  -0.043498        8.0        NaN   \n",
       "1973        NaN  -0.739120   0.275225   0.697625        6.0   0.074886   \n",
       "1974        NaN        NaN  -0.040592  -0.118391        8.0  -0.117050   \n",
       "1975        NaN  -0.124996   0.095273   0.242200        8.0   0.023881   \n",
       "1976        NaN   0.023079  -0.976493  -0.870644        8.0  -0.451283   \n",
       "1977        NaN  -0.196171  -0.578981  -0.203562        7.0  -0.673126   \n",
       "1978        7.0  -0.645218   0.354109  -0.104157        9.0   0.344572   \n",
       "1979        NaN   0.203171   0.226622   0.332481       10.0   0.022872   \n",
       "1980        NaN        NaN   1.076217   0.940583        7.0  -0.261668   \n",
       "1981        NaN        NaN   0.469571        NaN        7.0  -0.106057   \n",
       "1982        NaN   2.152784   0.232670   0.331534        1.0   0.273723   \n",
       "1983        NaN   2.995871   1.157415   1.234015        7.0   0.844000   \n",
       "1984        NaN  -0.618986  -0.029308        NaN        1.0  -0.430384   \n",
       "1985        NaN  -0.555872   0.028952  -0.166529        4.0   0.201376   \n",
       "1986        8.0  -0.888821   2.102174   0.546921        9.0   0.499608   \n",
       "1987        NaN        NaN  -0.710776        NaN        1.0  -0.254801   \n",
       "1988        NaN  -0.512331   0.664232   0.980403        1.0   2.119552   \n",
       "1989        7.0  -1.682440   3.396569   0.820769        9.0   1.734343   \n",
       "1990        NaN  -0.941491   0.668330   1.033846        6.0   0.253918   \n",
       "1991        NaN   0.047829        NaN   0.016124        7.0  -0.636452   \n",
       "1992        NaN        NaN  -0.045789  -0.457681        1.0   1.678332   \n",
       "1993        NaN  -1.961538   1.639694   1.571560        1.0   5.911557   \n",
       "1994        NaN        NaN   0.198985   0.327814        7.0        NaN   \n",
       "1995        NaN  -1.647647  -0.477716  -0.258534        8.0  -0.514951   \n",
       "1996        NaN  -0.453848   0.665826   0.972017        2.0   0.151838   \n",
       "1997        NaN  -0.163506  -0.608649        NaN        1.0   0.039211   \n",
       "1998        NaN        NaN  -1.006582        NaN        1.0  -0.190597   \n",
       "1999        NaN   0.074628  -0.776328  -0.350850        7.0  -0.498919   \n",
       "2000        NaN   1.129617   0.079880  -0.198706        9.0  -0.299925   \n",
       "\n",
       "      Feature_7  Feature_8  Feature_9  Feature_10      ...        Ret_175  \\\n",
       "Id                                                     ...                  \n",
       "1         75751     0.2254       11.0         NaN      ...      -0.002688   \n",
       "2         17369     0.0166       13.0         NaN      ...      -0.000129   \n",
       "3          8277     0.3650        9.0         5.0      ...      -0.000524   \n",
       "4         22508     0.2654       13.0         5.0      ...       0.000346   \n",
       "5         22423     0.2138       13.0         4.0      ...      -0.001235   \n",
       "6         24099     0.2064        8.0         NaN      ...       0.000242   \n",
       "7         39351     0.3650       13.0         NaN      ...       0.000326   \n",
       "8         92214     0.2119        8.0         5.0      ...      -0.000247   \n",
       "9         18418     0.3583        8.0         5.0      ...       0.000008   \n",
       "10        47637     0.2654        6.0         5.0      ...      -0.002510   \n",
       "11        51499     0.2654       13.0         NaN      ...       0.000735   \n",
       "12        79888     0.2109        8.0         NaN      ...       0.000016   \n",
       "13        63267     0.0158        8.0         NaN      ...       0.000027   \n",
       "14        35023     0.2138       10.0         NaN      ...       0.000295   \n",
       "15        76131     0.3318       14.0         4.0      ...      -0.000299   \n",
       "16        69564     0.3650        8.0         5.0      ...       0.000017   \n",
       "17        94022     0.0158        9.0         4.0      ...      -0.000388   \n",
       "18        16080     0.3583       10.0         5.0      ...      -0.001031   \n",
       "19        14259     0.2208        9.0         5.0      ...      -0.000869   \n",
       "20        65146     0.3418       10.0         1.0      ...       0.000444   \n",
       "21        47683     0.3418       11.0         NaN      ...       0.000002   \n",
       "22        35266     0.0171       17.0         NaN      ...      -0.000003   \n",
       "23        49660        NaN       10.0         NaN      ...      -0.000019   \n",
       "24        57773     0.2986        7.0         4.0      ...       0.000663   \n",
       "25        34161     0.0111       11.0         NaN      ...      -0.000016   \n",
       "26        64351     0.2087        7.0         1.0      ...       0.000491   \n",
       "27        19660     0.2323       10.0         2.0      ...       0.000615   \n",
       "28        94975     0.3650       10.0         NaN      ...      -0.008361   \n",
       "29        99483     0.3318        7.0         NaN      ...      -0.000247   \n",
       "30        40712     0.0158        9.0         NaN      ...       0.000293   \n",
       "...         ...        ...        ...         ...      ...            ...   \n",
       "1971      82574     0.3484        NaN         NaN      ...      -0.000004   \n",
       "1972      95570     0.2064       10.0         5.0      ...       0.000166   \n",
       "1973      94258     0.0163       17.0         NaN      ...       0.000284   \n",
       "1974       5453     0.2064        7.0         5.0      ...       0.000001   \n",
       "1975      29262     0.2254       10.0         NaN      ...       0.002835   \n",
       "1976      80829     0.2064        7.0         4.0      ...      -0.000271   \n",
       "1977      61797     0.3650        7.0         NaN      ...      -0.000005   \n",
       "1978      45523     0.2986       11.0         5.0      ...      -0.000479   \n",
       "1979      82781     0.2064       11.0         5.0      ...       0.000990   \n",
       "1980      67692     0.3451        9.0         NaN      ...      -0.000013   \n",
       "1981      84947     0.0166       12.0         NaN      ...      -0.000268   \n",
       "1982      54939     0.3583        9.0         6.0      ...      -0.000173   \n",
       "1983       8277     0.3318       11.0         5.0      ...       0.000428   \n",
       "1984      48389     0.0174       12.0         NaN      ...      -0.000264   \n",
       "1985      51499     0.0100        7.0         NaN      ...       0.000002   \n",
       "1986      76464        NaN       12.0         5.0      ...      -0.000340   \n",
       "1987      87553     0.2138        8.0         NaN      ...      -0.000001   \n",
       "1988      56524     0.3318       13.0         NaN      ...      -0.000247   \n",
       "1989      48481     0.2208       14.0         5.0      ...      -0.000075   \n",
       "1990      12347     0.2208       12.0         NaN      ...       0.000005   \n",
       "1991      50271     0.0174        8.0         5.0      ...      -0.000276   \n",
       "1992       5170     0.3484        8.0         6.0      ...       0.002935   \n",
       "1993       1344     0.3650       14.0         4.0      ...      -0.000245   \n",
       "1994      58773     0.2138        9.0         5.0      ...       0.000431   \n",
       "1995      24150     0.0098        4.0         5.0      ...       0.000781   \n",
       "1996      14937     0.2986        9.0         NaN      ...      -0.000615   \n",
       "1997      56348     0.0098       10.0         NaN      ...      -0.000008   \n",
       "1998      98649     0.2138        7.0         5.0      ...      -0.000546   \n",
       "1999      27376     0.0174        6.0         4.0      ...       0.000001   \n",
       "2000      22886     0.3484        8.0         5.0      ...       0.000853   \n",
       "\n",
       "           Ret_176       Ret_177       Ret_178   Ret_179   Ret_180  \\\n",
       "Id                                                                   \n",
       "1     2.246448e-03 -8.384789e-04 -6.953224e-04  0.000003 -0.001974   \n",
       "2     1.231983e-04  2.479729e-04  3.315418e-07  0.000003  0.000027   \n",
       "3    -3.942209e-04  1.162100e-04  5.322557e-04  0.000274  0.000784   \n",
       "4    -8.969682e-05  2.883115e-04 -1.281102e-04  0.000074  0.000341   \n",
       "5     2.723557e-05  2.449409e-03  8.619882e-06  0.001209 -0.000004   \n",
       "6     1.411510e-03  1.879851e-03 -9.458593e-04  0.000471  0.001193   \n",
       "7    -4.080826e-04  8.559887e-05 -1.192267e-05 -0.000006  0.000640   \n",
       "8    -2.496958e-04  9.815168e-06  1.620296e-05  0.000245  0.000006   \n",
       "9    -1.675738e-05 -6.565766e-06 -3.834451e-04 -0.000929  0.000184   \n",
       "10    6.401681e-04  6.231028e-04  6.077426e-04 -0.001252 -0.000597   \n",
       "11   -1.110030e-03  1.739014e-04  1.207965e-05  0.000357  0.000002   \n",
       "12   -6.732017e-04  2.040139e-03 -7.816066e-06  0.000685 -0.000356   \n",
       "13    5.338005e-06 -3.320290e-04  1.663772e-04 -0.000008 -0.000320   \n",
       "14   -1.857928e-03  1.133055e-03 -1.288622e-03 -0.000433 -0.000574   \n",
       "15   -5.690433e-04 -1.880131e-04 -8.045307e-06 -0.000771  0.000020   \n",
       "16   -1.566804e-04  1.592441e-04  1.500476e-04 -0.000325  0.000157   \n",
       "17    1.393200e-04 -1.439964e-04  6.674850e-04  0.000009  0.000137   \n",
       "18    1.033490e-04 -7.209001e-04 -4.000919e-04 -0.000510 -0.000102   \n",
       "19    6.581058e-04  2.950673e-06  3.020044e-03  0.000438 -0.000638   \n",
       "20   -2.195779e-04  5.612446e-04  5.640549e-04 -0.000682  0.000028   \n",
       "21    7.614084e-04  1.255061e-03 -1.009536e-03 -0.001264  0.001275   \n",
       "22   -1.831635e-03 -4.656236e-04 -8.925414e-04 -0.000930  0.000445   \n",
       "23    2.559671e-04 -1.547616e-05  2.179806e-04  0.000006  0.000129   \n",
       "24   -3.362421e-03 -2.675504e-03  2.674716e-03  0.002692 -0.003376   \n",
       "25    5.590299e-04  5.731391e-04  1.153140e-03 -0.000002  0.000559   \n",
       "26   -5.948549e-04 -3.920858e-04 -9.911355e-05 -0.000400 -0.000002   \n",
       "27   -3.296061e-04 -9.017426e-04 -3.611286e-04  0.000525 -0.000180   \n",
       "28   -7.114985e-03  1.186144e-03 -7.075140e-03 -0.005854 -0.003510   \n",
       "29   -8.797364e-04  6.278138e-04 -7.483020e-04 -0.000504 -0.000260   \n",
       "30   -1.157849e-05 -1.215498e-06  5.866008e-05 -0.000033  0.000002   \n",
       "...            ...           ...           ...       ...       ...   \n",
       "1971  3.577820e-04 -3.596965e-04  7.129191e-04 -0.002467 -0.000701   \n",
       "1972  5.791017e-06  9.837415e-04  6.363922e-04 -0.000007  0.000815   \n",
       "1973  2.857951e-04 -1.697916e-07  2.008845e-05  0.000298  0.000292   \n",
       "1974  2.850987e-04  8.670662e-04  1.459405e-03 -0.000295  0.000293   \n",
       "1975 -3.943045e-06  5.623422e-04  5.668099e-04  0.000592  0.001721   \n",
       "1976  1.276656e-04  1.023693e-03  1.339725e-04 -0.000376  0.000737   \n",
       "1977 -6.818950e-06  1.184736e-05 -9.196969e-04 -0.000009  0.000012   \n",
       "1978 -4.791143e-04  9.550447e-04  1.059973e-05  0.000003 -0.000484   \n",
       "1979  1.146207e-06  4.923621e-04 -2.438922e-04 -0.000987  0.000506   \n",
       "1980 -3.340021e-04  2.279709e-04  2.336519e-04  0.000213 -0.000011   \n",
       "1981 -4.550989e-06 -1.312794e-04  3.241671e-06  0.000115 -0.000003   \n",
       "1982 -1.902923e-04  1.432672e-03 -1.692896e-04 -0.000888 -0.000721   \n",
       "1983 -2.058026e-04  5.725216e-06 -4.422490e-04 -0.000227 -0.000213   \n",
       "1984  1.027195e-04 -2.549077e-05  8.745209e-05  0.000197  0.000596   \n",
       "1985  8.286784e-04 -1.658063e-03 -6.814984e-06 -0.000839 -0.000841   \n",
       "1986  6.717882e-04  9.956740e-04 -2.771507e-06  0.000007 -0.000346   \n",
       "1987 -2.173213e-07 -3.025734e-04 -3.073193e-04  0.000273 -0.000593   \n",
       "1988  2.492693e-04 -4.323564e-06 -4.955796e-06 -0.000015 -0.000258   \n",
       "1989  7.844714e-05 -5.023798e-04  1.572674e-07  0.000160  0.000505   \n",
       "1990  1.403474e-05  9.455745e-06 -1.323697e-05  0.000191 -0.000175   \n",
       "1991 -2.637521e-04 -8.320440e-04  8.221117e-04  0.000278 -0.000852   \n",
       "1992 -2.196378e-03 -1.474602e-03 -5.412621e-06 -0.000748  0.000007   \n",
       "1993 -8.472979e-06 -9.385212e-06 -2.563526e-04 -0.000487  0.000468   \n",
       "1994  2.335623e-04 -9.486519e-04 -5.435486e-06 -0.000213 -0.001219   \n",
       "1995  8.350968e-04  2.820332e-04 -5.750897e-04 -0.000003  0.000271   \n",
       "1996 -4.085132e-04 -1.158836e-04  2.958219e-04 -0.000185 -0.000416   \n",
       "1997  1.038278e-03  6.981343e-04  6.778698e-06  0.000300  0.000041   \n",
       "1998 -3.580614e-03 -2.188811e-03 -5.757392e-03 -0.004077  0.004082   \n",
       "1999  3.967419e-06  1.029781e-03 -1.024820e-03  0.001048 -0.000005   \n",
       "2000 -1.687280e-03  1.249581e-06 -9.508965e-06 -0.000840 -0.000004   \n",
       "\n",
       "      Ret_PlusOne  Ret_PlusTwo  Weight_Intraday  Weight_Daily  \n",
       "Id                                                             \n",
       "1       -0.019512     0.028846     1.251508e+06  1.564385e+06  \n",
       "2       -0.002939    -0.010253     1.733950e+06  2.167438e+06  \n",
       "3       -0.024791     0.015711     1.529197e+06  1.911497e+06  \n",
       "4       -0.005680    -0.002190     1.711569e+06  2.139462e+06  \n",
       "5        0.036104    -0.026552     1.267270e+06  1.584088e+06  \n",
       "6        0.031098    -0.006551     1.431110e+06  1.788888e+06  \n",
       "7       -0.011105    -0.030745     1.719166e+06  2.148958e+06  \n",
       "8        0.020268    -0.059093     1.349917e+06  1.687396e+06  \n",
       "9       -0.009348    -0.024755     1.536680e+06  1.920849e+06  \n",
       "10       0.022407    -0.010674     1.370804e+06  1.713505e+06  \n",
       "11       0.002055     0.013504     1.525034e+06  1.906293e+06  \n",
       "12       0.097741     0.035604     1.529522e+06  1.911903e+06  \n",
       "13       0.000599    -0.027103     1.813731e+06  2.267164e+06  \n",
       "14      -0.010936    -0.019700     1.460081e+06  1.825101e+06  \n",
       "15       0.001028    -0.001756     1.555965e+06  1.944956e+06  \n",
       "16       0.004728    -0.016166     1.423454e+06  1.779318e+06  \n",
       "17       0.009090    -0.003522     1.861237e+06  2.326546e+06  \n",
       "18      -0.010067    -0.006406     1.436242e+06  1.795303e+06  \n",
       "19       0.003166    -0.007578     1.675006e+06  2.093757e+06  \n",
       "20       0.000229     0.004250     1.695051e+06  2.118814e+06  \n",
       "21      -0.007368     0.001143     1.511918e+06  1.889897e+06  \n",
       "22      -0.023468     0.004602     1.450708e+06  1.813385e+06  \n",
       "23       0.005781     0.016854     1.501551e+06  1.876939e+06  \n",
       "24       0.076162     0.013566     1.208516e+06  1.510645e+06  \n",
       "25      -0.005204     0.014411     1.778732e+06  2.223415e+06  \n",
       "26       0.010771     0.004254     1.513133e+06  1.891416e+06  \n",
       "27      -0.032365    -0.017119     1.557176e+06  1.946470e+06  \n",
       "28       0.129496    -0.012954     1.340404e+06  1.675506e+06  \n",
       "29       0.003828    -0.007302     1.344794e+06  1.680992e+06  \n",
       "30       0.023321    -0.002465     1.895309e+06  2.369136e+06  \n",
       "...           ...          ...              ...           ...  \n",
       "1971    -0.003744    -0.021519     1.369248e+06  1.711560e+06  \n",
       "1972     0.022971     0.030974     1.256701e+06  1.570876e+06  \n",
       "1973    -0.010891    -0.004293     1.890853e+06  2.363567e+06  \n",
       "1974     0.015722    -0.013927     1.490222e+06  1.862777e+06  \n",
       "1975    -0.014878    -0.034630     1.272266e+06  1.590332e+06  \n",
       "1976     0.012572    -0.054967     1.198448e+06  1.498059e+06  \n",
       "1977    -0.017264     0.000677     1.623057e+06  2.028821e+06  \n",
       "1978    -0.041075     0.008291     1.309402e+06  1.636753e+06  \n",
       "1979     0.002806    -0.004663     1.755921e+06  2.194901e+06  \n",
       "1980     0.007115    -0.002349     1.411992e+06  1.764990e+06  \n",
       "1981    -0.010295    -0.053464     1.622031e+06  2.027539e+06  \n",
       "1982    -0.009063     0.010975     1.679530e+06  2.099413e+06  \n",
       "1983    -0.010205    -0.003287     1.580700e+06  1.975874e+06  \n",
       "1984    -0.002402     0.003311     1.802324e+06  2.252905e+06  \n",
       "1985    -0.010317     0.005009     1.469613e+06  1.837016e+06  \n",
       "1986    -0.011328    -0.003870     1.279307e+06  1.599133e+06  \n",
       "1987    -0.017155     0.002826     1.728225e+06  2.160282e+06  \n",
       "1988    -0.015996     0.008929     1.875855e+06  2.344819e+06  \n",
       "1989    -0.027150     0.015245     1.514668e+06  1.893334e+06  \n",
       "1990    -0.010499     0.009273     1.949350e+06  2.436687e+06  \n",
       "1991     0.024224     0.014187     1.424179e+06  1.780223e+06  \n",
       "1992     0.011625     0.018633     1.252724e+06  1.565906e+06  \n",
       "1993     0.001505     0.004192     1.644097e+06  2.055121e+06  \n",
       "1994     0.006588    -0.009084     1.589009e+06  1.986261e+06  \n",
       "1995    -0.021563     0.024478     1.251844e+06  1.564805e+06  \n",
       "1996    -0.018140    -0.005236     1.479917e+06  1.849896e+06  \n",
       "1997    -0.019756    -0.010661     1.550242e+06  1.937802e+06  \n",
       "1998    -0.030099     0.027257     1.439026e+06  1.798783e+06  \n",
       "1999     0.001781    -0.016628     1.639155e+06  2.048944e+06  \n",
       "2000    -0.029227     0.045893     1.256048e+06  1.570060e+06  \n",
       "\n",
       "[2000 rows x 210 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loaddata()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((400, 146), (400, 62))\n"
     ]
    }
   ],
   "source": [
    "data = loaddata('train.csv', 0.01)\n",
    "\n",
    "X = data.loc[:, 'Feature_1':'Ret_120'].values\n",
    "y = data.loc[:, 'Ret_121':'Ret_PlusTwo'].values\n",
    "\n",
    "daily_weights = data['Weight_Daily'].values\n",
    "intraday_weights = data['Weight_Intraday'].values\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MICE imputer, recently added to sklean (https://github.com/scikit-learn/scikit-learn/pull/8478)\n",
    "# not released yet\n",
    "\n",
    "from __future__ import division\n",
    "from time import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from scipy import sparse\n",
    "from scipy import stats\n",
    "from collections import namedtuple\n",
    "\n",
    "from sklearn.base import clone, BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import check_array, check_random_state, safe_indexing\n",
    "from sklearn.utils.validation import FLOAT_DTYPES, check_is_fitted\n",
    "\n",
    "MICETriplet = namedtuple('MICETriplet', ['feat_idx',\n",
    "                                         'neighbor_feat_idx',\n",
    "                                         'predictor'])\n",
    "\n",
    "def _get_mask(X, value_to_mask):\n",
    "    \"\"\"Compute the boolean mask X == missing_values.\"\"\"\n",
    "    if value_to_mask == \"NaN\" or np.isnan(value_to_mask):\n",
    "        return np.isnan(X)\n",
    "    else:\n",
    "        return X == value_to_mask\n",
    "\n",
    "def _most_frequent(array, extra_value, n_repeat):\n",
    "    \"\"\"Compute the most frequent value in a 1d array extended with\n",
    "       [extra_value] * n_repeat, where extra_value is assumed to be not part\n",
    "       of the array.\"\"\"\n",
    "    # Compute the most frequent value in array only\n",
    "    if array.size > 0:\n",
    "        mode = stats.mode(array)\n",
    "        most_frequent_value = mode[0][0]\n",
    "        most_frequent_count = mode[1][0]\n",
    "    else:\n",
    "        most_frequent_value = 0\n",
    "        most_frequent_count = 0\n",
    "\n",
    "    # Compare to array + [extra_value] * n_repeat\n",
    "    if most_frequent_count == 0 and n_repeat == 0:\n",
    "        return np.nan\n",
    "    elif most_frequent_count < n_repeat:\n",
    "        return extra_value\n",
    "    elif most_frequent_count > n_repeat:\n",
    "        return most_frequent_value\n",
    "    elif most_frequent_count == n_repeat:\n",
    "        # Ties the breaks. Copy the behaviour of scipy.stats.mode\n",
    "        if most_frequent_value < extra_value:\n",
    "            return most_frequent_value\n",
    "        else:\n",
    "            return extra_value\n",
    "\n",
    "\n",
    "class SimpleImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Imputation transformer for completing missing values.\n",
    "    Read more in the :ref:`User Guide <impute>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    missing_values : integer or \"NaN\", optional (default=\"NaN\")\n",
    "        The placeholder for the missing values. All occurrences of\n",
    "        `missing_values` will be imputed. For missing values encoded as np.nan,\n",
    "        use the string value \"NaN\".\n",
    "    strategy : string, optional (default=\"mean\")\n",
    "        The imputation strategy.\n",
    "        - If \"mean\", then replace missing values using the mean along\n",
    "          each column.\n",
    "        - If \"median\", then replace missing values using the median along\n",
    "          each column.\n",
    "        - If \"most_frequent\", then replace missing using the most frequent\n",
    "          value along each column.\n",
    "    verbose : integer, optional (default=0)\n",
    "        Controls the verbosity of the imputer.\n",
    "    copy : boolean, optional (default=True)\n",
    "        If True, a copy of X will be created. If False, imputation will\n",
    "        be done in-place whenever possible. Note that, in the following cases,\n",
    "        a new copy will always be made, even if `copy=False`:\n",
    "        - If X is not an array of floating values;\n",
    "        - If X is sparse and `missing_values=0`;\n",
    "        - If X is encoded as a CSR matrix.\n",
    "    Attributes\n",
    "    ----------\n",
    "    statistics_ : array of shape (n_features,)\n",
    "        The imputation fill value for each feature.\n",
    "    Notes\n",
    "    -----\n",
    "    Columns which only contained missing values at `fit` are discarded upon\n",
    "    `transform`.\n",
    "    \"\"\"\n",
    "    def __init__(self, missing_values=\"NaN\", strategy=\"mean\",\n",
    "                 verbose=0, copy=True):\n",
    "        self.missing_values = missing_values\n",
    "        self.strategy = strategy\n",
    "        self.verbose = verbose\n",
    "        self.copy = copy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit the imputer on X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            Input data, where ``n_samples`` is the number of samples and\n",
    "            ``n_features`` is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        self : SimpleImputer\n",
    "        \"\"\"\n",
    "        # Check parameters\n",
    "        allowed_strategies = [\"mean\", \"median\", \"most_frequent\"]\n",
    "        if self.strategy not in allowed_strategies:\n",
    "            raise ValueError(\"Can only use these strategies: {0} \"\n",
    "                             \" got strategy={1}\".format(allowed_strategies,\n",
    "                                                        self.strategy))\n",
    "\n",
    "        X = check_array(X, accept_sparse='csc', dtype=FLOAT_DTYPES,\n",
    "                        force_all_finite=False\n",
    "                        if self.missing_values == 'NaN'\n",
    "                        or np.isnan(self.missing_values) else True)\n",
    "\n",
    "        if sparse.issparse(X):\n",
    "            self.statistics_ = self._sparse_fit(X,\n",
    "                                                self.strategy,\n",
    "                                                self.missing_values)\n",
    "        else:\n",
    "            self.statistics_ = self._dense_fit(X,\n",
    "                                               self.strategy,\n",
    "                                               self.missing_values)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _sparse_fit(self, X, strategy, missing_values):\n",
    "        \"\"\"Fit the transformer on sparse data.\"\"\"\n",
    "        # Count the zeros\n",
    "        if missing_values == 0:\n",
    "            n_zeros_axis = np.zeros(X.shape[1], dtype=int)\n",
    "        else:\n",
    "            n_zeros_axis = X.shape[0] - np.diff(X.indptr)\n",
    "\n",
    "        # Mean\n",
    "        if strategy == \"mean\":\n",
    "            if missing_values != 0:\n",
    "                n_non_missing = n_zeros_axis\n",
    "\n",
    "                # Mask the missing elements\n",
    "                mask_missing_values = _get_mask(X.data, missing_values)\n",
    "                mask_valids = np.logical_not(mask_missing_values)\n",
    "\n",
    "                # Sum only the valid elements\n",
    "                new_data = X.data.copy()\n",
    "                new_data[mask_missing_values] = 0\n",
    "                X = sparse.csc_matrix((new_data, X.indices, X.indptr),\n",
    "                                      copy=False)\n",
    "                sums = X.sum(axis=0)\n",
    "\n",
    "                # Count the elements != 0\n",
    "                mask_non_zeros = sparse.csc_matrix(\n",
    "                    (mask_valids.astype(np.float64),\n",
    "                     X.indices,\n",
    "                     X.indptr), copy=False)\n",
    "                s = mask_non_zeros.sum(axis=0)\n",
    "                n_non_missing = np.add(n_non_missing, s)\n",
    "\n",
    "            else:\n",
    "                sums = X.sum(axis=0)\n",
    "                n_non_missing = np.diff(X.indptr)\n",
    "\n",
    "            # Ignore the error, columns with a np.nan statistics_\n",
    "            # are not an error at this point. These columns will\n",
    "            # be removed in transform\n",
    "            with np.errstate(all=\"ignore\"):\n",
    "                return np.ravel(sums) / np.ravel(n_non_missing)\n",
    "\n",
    "        # Median + Most frequent\n",
    "        else:\n",
    "            # Remove the missing values, for each column\n",
    "            columns_all = np.hsplit(X.data, X.indptr[1:-1])\n",
    "            mask_missing_values = _get_mask(X.data, missing_values)\n",
    "            mask_valids = np.hsplit(np.logical_not(mask_missing_values),\n",
    "                                    X.indptr[1:-1])\n",
    "\n",
    "            # astype necessary for bug in numpy.hsplit before v1.9\n",
    "            columns = [col[mask.astype(bool, copy=False)]\n",
    "                       for col, mask in zip(columns_all, mask_valids)]\n",
    "\n",
    "            # Median\n",
    "            if strategy == \"median\":\n",
    "                median = np.empty(len(columns))\n",
    "                for i, column in enumerate(columns):\n",
    "                    median[i] = _get_median(column, n_zeros_axis[i])\n",
    "\n",
    "                return median\n",
    "\n",
    "            # Most frequent\n",
    "            elif strategy == \"most_frequent\":\n",
    "                most_frequent = np.empty(len(columns))\n",
    "\n",
    "                for i, column in enumerate(columns):\n",
    "                    most_frequent[i] = _most_frequent(column,\n",
    "                                                      0,\n",
    "                                                      n_zeros_axis[i])\n",
    "\n",
    "                return most_frequent\n",
    "\n",
    "    def _dense_fit(self, X, strategy, missing_values):\n",
    "        \"\"\"Fit the transformer on dense data.\"\"\"\n",
    "        X = check_array(X, force_all_finite=False\n",
    "                        if self.missing_values == 'NaN'\n",
    "                        or np.isnan(self.missing_values) else True)\n",
    "        mask = _get_mask(X, missing_values)\n",
    "        masked_X = ma.masked_array(X, mask=mask)\n",
    "\n",
    "        # Mean\n",
    "        if strategy == \"mean\":\n",
    "            mean_masked = np.ma.mean(masked_X, axis=0)\n",
    "            # Avoid the warning \"Warning: converting a masked element to nan.\"\n",
    "            mean = np.ma.getdata(mean_masked)\n",
    "            mean[np.ma.getmask(mean_masked)] = np.nan\n",
    "\n",
    "            return mean\n",
    "\n",
    "        # Median\n",
    "        elif strategy == \"median\":\n",
    "            median_masked = np.ma.median(masked_X, axis=0)\n",
    "            # Avoid the warning \"Warning: converting a masked element to nan.\"\n",
    "            median = np.ma.getdata(median_masked)\n",
    "            median[np.ma.getmaskarray(median_masked)] = np.nan\n",
    "\n",
    "            return median\n",
    "\n",
    "        # Most frequent\n",
    "        elif strategy == \"most_frequent\":\n",
    "            # scipy.stats.mstats.mode cannot be used because it will no work\n",
    "            # properly if the first element is masked and if its frequency\n",
    "            # is equal to the frequency of the most frequent valid element\n",
    "            # See https://github.com/scipy/scipy/issues/2636\n",
    "\n",
    "            # To be able access the elements by columns\n",
    "            X = X.transpose()\n",
    "            mask = mask.transpose()\n",
    "\n",
    "            most_frequent = np.empty(X.shape[0])\n",
    "\n",
    "            for i, (row, row_mask) in enumerate(zip(X[:], mask[:])):\n",
    "                row_mask = np.logical_not(row_mask).astype(np.bool)\n",
    "                row = row[row_mask]\n",
    "                most_frequent[i] = _most_frequent(row, np.nan, 0)\n",
    "\n",
    "            return most_frequent\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Impute all missing values in X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            The input data to complete.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'statistics_')\n",
    "        X = check_array(X, accept_sparse='csc', dtype=FLOAT_DTYPES,\n",
    "                        force_all_finite=False\n",
    "                        if self.missing_values == 'NaN'\n",
    "                        or np.isnan(self.missing_values) else True,\n",
    "                        copy=self.copy)\n",
    "        statistics = self.statistics_\n",
    "        if X.shape[1] != statistics.shape[0]:\n",
    "            raise ValueError(\"X has %d features per sample, expected %d\"\n",
    "                             % (X.shape[1], self.statistics_.shape[0]))\n",
    "\n",
    "        # Delete the invalid columns\n",
    "        invalid_mask = np.isnan(statistics)\n",
    "        valid_mask = np.logical_not(invalid_mask)\n",
    "        valid_statistics = statistics[valid_mask]\n",
    "        valid_statistics_indexes = np.flatnonzero(valid_mask)\n",
    "        missing = np.arange(X.shape[1])[invalid_mask]\n",
    "\n",
    "        if invalid_mask.any():\n",
    "            if self.verbose:\n",
    "                warnings.warn(\"Deleting features without \"\n",
    "                              \"observed values: %s\" % missing)\n",
    "            X = X[:, valid_statistics_indexes]\n",
    "\n",
    "        # Do actual imputation\n",
    "        if sparse.issparse(X) and self.missing_values != 0:\n",
    "            mask = _get_mask(X.data, self.missing_values)\n",
    "            indexes = np.repeat(np.arange(len(X.indptr) - 1, dtype=np.int),\n",
    "                                np.diff(X.indptr))[mask]\n",
    "\n",
    "            X.data[mask] = valid_statistics[indexes].astype(X.dtype,\n",
    "                                                            copy=False)\n",
    "        else:\n",
    "            if sparse.issparse(X):\n",
    "                X = X.toarray()\n",
    "\n",
    "            mask = _get_mask(X, self.missing_values)\n",
    "            n_missing = np.sum(mask, axis=0)\n",
    "            values = np.repeat(valid_statistics, n_missing)\n",
    "\n",
    "            coordinates = np.where(mask.transpose())[::-1]\n",
    "\n",
    "            X[coordinates] = values\n",
    "\n",
    "        return X    \n",
    "    \n",
    "\n",
    "class MICEImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"MICE transformer to impute missing values.\n",
    "    Basic implementation of MICE (Multivariate Imputations by Chained\n",
    "    Equations) package from R. This version assumes all of the features are\n",
    "    Gaussian.\n",
    "    Parameters\n",
    "    ----------\n",
    "    missing_values : int or \"NaN\", optional (default=\"NaN\")\n",
    "        The placeholder for the missing values. All occurrences of\n",
    "        ``missing_values`` will be imputed. For missing values encoded as\n",
    "        np.nan, use the string value \"NaN\".\n",
    "    imputation_order : str, optional (default=\"ascending\")\n",
    "        The order in which the features will be imputed. Possible values:\n",
    "        \"ascending\"\n",
    "            From features with fewest missing values to most.\n",
    "        \"descending\"\n",
    "            From features with most missing values to fewest.\n",
    "        \"roman\"\n",
    "            Left to right.\n",
    "        \"arabic\"\n",
    "            Right to left.\n",
    "        \"random\"\n",
    "            A random order for each round.\n",
    "    n_imputations : int, optional (default=100)\n",
    "        Number of MICE rounds to perform, the results of which will be\n",
    "        used in the final average.\n",
    "    n_burn_in : int, optional (default=10)\n",
    "        Number of initial MICE rounds to perform the results of which\n",
    "        will not be returned.\n",
    "    predictor : estimator object, default=BayesianRidge()\n",
    "        The predictor to use at each step of the round-robin imputation.\n",
    "        It must support ``return_std`` in its ``predict`` method.\n",
    "    n_nearest_features : int, optional (default=None)\n",
    "        Number of other features to use to estimate the missing values of\n",
    "        the each feature column. Nearness between features is measured using\n",
    "        the absolute correlation coefficient between each feature pair (after\n",
    "        initial imputation). Can provide significant speed-up when the number\n",
    "        of features is huge. If ``None``, all features will be used.\n",
    "    initial_strategy : str, optional (default=\"mean\")\n",
    "        Which strategy to use to initialize the missing values. Same as the\n",
    "        ``strategy`` parameter in :class:`sklearn.preprocessing.Imputer`\n",
    "        Valid values: {\"mean\", \"median\", or \"most_frequent\"}.\n",
    "    min_value : float, optional (default=None)\n",
    "        Minimum possible imputed value. Default of ``None`` will set minimum\n",
    "        to negative infinity.\n",
    "    max_value : float, optional (default=None)\n",
    "        Maximum possible imputed value. Default of ``None`` will set maximum\n",
    "        to positive infinity.\n",
    "    verbose : int, optional (default=0)\n",
    "        Verbosity flag, controls the debug messages that are issued\n",
    "        as functions are evaluated. The higher, the more verbose. Can be 0, 1,\n",
    "        or 2.\n",
    "    random_state : int, RandomState instance or None, optional (default=None)\n",
    "        The seed of the pseudo random number generator to use when shuffling\n",
    "        the data.  If int, random_state is the seed used by the random number\n",
    "        generator; If RandomState instance, random_state is the random number\n",
    "        generator; If None, the random number generator is the RandomState\n",
    "        instance used by ``np.random``.\n",
    "    Attributes\n",
    "    ----------\n",
    "    initial_imputer_ : object of class :class:`sklearn.preprocessing.Imputer`'\n",
    "        The imputer used to initialize the missing values.\n",
    "    imputation_sequence_ : list of tuples\n",
    "        Each tuple has ``(feat_idx, neighbor_feat_idx, predictor)``, where\n",
    "        ``feat_idx`` is the current feature to be imputed,\n",
    "        ``neighbor_feat_idx`` is the array of other features used to impute the\n",
    "        current feature, and ``predictor`` is the trained predictor used for\n",
    "        the imputation.\n",
    "    Notes\n",
    "    -----\n",
    "    The R version of MICE does not have inductive functionality, i.e. first\n",
    "    fitting on ``X_train`` and then transforming any ``X_test`` without\n",
    "    additional fitting. We do this by storing each feature's predictor during\n",
    "    the round-robin ``fit`` phase, and predicting without refitting (in order)\n",
    "    during the ``transform`` phase.\n",
    "    Features which contain all missing values at ``fit`` are discarded upon\n",
    "    ``transform``.\n",
    "    Features with missing values in transform which did not have any missing\n",
    "    values in fit will be imputed with the initial imputation method only.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] `Stef van Buuren, Karin Groothuis-Oudshoorn (2011). \"mice:\n",
    "        Multivariate Imputation by Chained Equations in R\". Journal of\n",
    "        Statistical Software 45: 1-67.\n",
    "        <https://www.jstatsoft.org/article/view/v045i03>`_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 missing_values='NaN',\n",
    "                 imputation_order='ascending',\n",
    "                 n_imputations=100,\n",
    "                 n_burn_in=10,\n",
    "                 predictor=None,\n",
    "                 n_nearest_features=None,\n",
    "                 initial_strategy=\"mean\",\n",
    "                 min_value=None,\n",
    "                 max_value=None,\n",
    "                 verbose=False,\n",
    "                 random_state=None):\n",
    "\n",
    "        self.missing_values = missing_values\n",
    "        self.imputation_order = imputation_order\n",
    "        self.n_imputations = n_imputations\n",
    "        self.n_burn_in = n_burn_in\n",
    "        self.predictor = predictor\n",
    "        self.n_nearest_features = n_nearest_features\n",
    "        self.initial_strategy = initial_strategy\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "        self.verbose = verbose\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def _impute_one_feature(self,\n",
    "                            X_filled,\n",
    "                            mask_missing_values,\n",
    "                            feat_idx,\n",
    "                            neighbor_feat_idx,\n",
    "                            predictor=None,\n",
    "                            fit_mode=True):\n",
    "        \"\"\"Impute a single feature from the others provided.\n",
    "        This function predicts the missing values of one of the features using\n",
    "        the current estimates of all the other features. The ``predictor`` must\n",
    "        support ``return_std=True`` in its ``predict`` method for this function\n",
    "        to work.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_filled : ndarray\n",
    "            Input data with the most recent imputations.\n",
    "        mask_missing_values : ndarray\n",
    "            Input data's missing indicator matrix.\n",
    "        feat_idx : int\n",
    "            Index of the feature currently being imputed.\n",
    "        neighbor_feat_idx : ndarray\n",
    "            Indices of the features to be used in imputing ``feat_idx``.\n",
    "        predictor : object\n",
    "            The predictor to use at this step of the round-robin imputation.\n",
    "            It must support ``return_std`` in its ``predict`` method.\n",
    "            If None, it will be cloned from self._predictor.\n",
    "        fit_mode : boolean, default=True\n",
    "            Whether to fit and predict with the predictor or just predict.\n",
    "        Returns\n",
    "        -------\n",
    "        X_filled : ndarray\n",
    "            Input data with ``X_filled[missing_row_mask, feat_idx]`` updated.\n",
    "        predictor : predictor with sklearn API\n",
    "            The fitted predictor used to impute\n",
    "            ``X_filled[missing_row_mask, feat_idx]``.\n",
    "        \"\"\"\n",
    "\n",
    "        # if nothing is missing, just return the default\n",
    "        # (should not happen at fit time because feat_ids would be excluded)\n",
    "        missing_row_mask = mask_missing_values[:, feat_idx]\n",
    "        if not np.any(missing_row_mask):\n",
    "            return X_filled, predictor\n",
    "\n",
    "        if predictor is None and fit_mode is False:\n",
    "            raise ValueError(\"If fit_mode is False, then an already-fitted \"\n",
    "                             \"predictor should be passed in.\")\n",
    "\n",
    "        if predictor is None:\n",
    "            predictor = clone(self._predictor)\n",
    "\n",
    "        if fit_mode:\n",
    "            X_train = safe_indexing(X_filled[:, neighbor_feat_idx],\n",
    "                                    ~missing_row_mask)\n",
    "            y_train = safe_indexing(X_filled[:, feat_idx],\n",
    "                                    ~missing_row_mask)\n",
    "            predictor.fit(X_train, y_train)\n",
    "\n",
    "        # get posterior samples\n",
    "        X_test = safe_indexing(X_filled[:, neighbor_feat_idx],\n",
    "                               missing_row_mask)\n",
    "        mus, sigmas = predictor.predict(X_test, return_std=True)\n",
    "        good_sigmas = sigmas > 0\n",
    "        imputed_values = np.zeros(mus.shape, dtype=X_filled.dtype)\n",
    "        imputed_values[~good_sigmas] = mus[~good_sigmas]\n",
    "        imputed_values[good_sigmas] = self.random_state_.normal(\n",
    "            loc=mus[good_sigmas], scale=sigmas[good_sigmas])\n",
    "\n",
    "        # clip the values\n",
    "        imputed_values = np.clip(imputed_values,\n",
    "                                 self._min_value,\n",
    "                                 self._max_value)\n",
    "\n",
    "        # update the feature\n",
    "        X_filled[missing_row_mask, feat_idx] = imputed_values\n",
    "        return X_filled, predictor\n",
    "\n",
    "    def _get_neighbor_feat_idx(self,\n",
    "                               n_features,\n",
    "                               feat_idx,\n",
    "                               abs_corr_mat):\n",
    "        \"\"\"Get a list of other features to predict ``feat_idx``.\n",
    "        If self.n_nearest_features is less than or equal to the total\n",
    "        number of features, then use a probability proportional to the absolute\n",
    "        correlation between ``feat_idx`` and each other feature to randomly\n",
    "        choose a subsample of the other features (without replacement).\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_features : int\n",
    "            Number of features in ``X``.\n",
    "        feat_idx : int\n",
    "            Index of the feature currently being imputed.\n",
    "        abs_corr_mat : ndarray, shape (n_features, n_features)\n",
    "            Absolute correlation matrix of ``X``. The diagonal has been zeroed\n",
    "            out and each feature has been normalized to sum to 1. Can be None.\n",
    "        Returns\n",
    "        -------\n",
    "        neighbor_feat_idx : array-like\n",
    "            The features to use to impute ``feat_idx``.\n",
    "        \"\"\"\n",
    "        if (self.n_nearest_features is not None and\n",
    "                self.n_nearest_features < n_features):\n",
    "            p = abs_corr_mat[:, feat_idx]\n",
    "            neighbor_feat_idx = self.random_state_.choice(\n",
    "                np.arange(n_features), self.n_nearest_features, replace=False,\n",
    "                p=p)\n",
    "        else:\n",
    "            inds_left = np.arange(feat_idx)\n",
    "            inds_right = np.arange(feat_idx + 1, n_features)\n",
    "            neighbor_feat_idx = np.concatenate((inds_left, inds_right))\n",
    "        return neighbor_feat_idx\n",
    "\n",
    "    def _get_ordered_idx(self, mask_missing_values):\n",
    "        \"\"\"Decide in what order we will update the features.\n",
    "        As a homage to the MICE R package, we will have 4 main options of\n",
    "        how to order the updates, and use a random order if anything else\n",
    "        is specified.\n",
    "        Also, this function skips features which have no missing values.\n",
    "        Parameters\n",
    "        ----------\n",
    "        mask_missing_values : array-like, shape (n_samples, n_features)\n",
    "            Input data's missing indicator matrix, where \"n_samples\" is the\n",
    "            number of samples and \"n_features\" is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        ordered_idx : ndarray, shape (n_features,)\n",
    "            The order in which to impute the features.\n",
    "        \"\"\"\n",
    "        frac_of_missing_values = mask_missing_values.mean(axis=0)\n",
    "        missing_values_idx = np.nonzero(frac_of_missing_values)[0]\n",
    "        if self.imputation_order == 'roman':\n",
    "            ordered_idx = missing_values_idx\n",
    "        elif self.imputation_order == 'arabic':\n",
    "            ordered_idx = missing_values_idx[::-1]\n",
    "        elif self.imputation_order == 'ascending':\n",
    "            n = len(frac_of_missing_values) - len(missing_values_idx)\n",
    "            ordered_idx = np.argsort(frac_of_missing_values,\n",
    "                                     kind='mergesort')[n:][::-1]\n",
    "        elif self.imputation_order == 'descending':\n",
    "            n = len(frac_of_missing_values) - len(missing_values_idx)\n",
    "            ordered_idx = np.argsort(frac_of_missing_values,\n",
    "                                     kind='mergesort')[n:]\n",
    "        elif self.imputation_order == 'random':\n",
    "            ordered_idx = missing_values_idx\n",
    "            self.random_state_.shuffle(ordered_idx)\n",
    "        else:\n",
    "            raise ValueError(\"Got an invalid imputation order: '{0}'. It must \"\n",
    "                             \"be one of the following: 'roman', 'arabic', \"\n",
    "                             \"'ascending', 'descending', or \"\n",
    "                             \"'random'.\".format(self.imputation_order))\n",
    "        return ordered_idx\n",
    "\n",
    "    def _get_abs_corr_mat(self, X_filled, tolerance=1e-6):\n",
    "        \"\"\"Get absolute correlation matrix between features.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_filled : ndarray, shape (n_samples, n_features)\n",
    "            Input data with the most recent imputations.\n",
    "        tolerance : float, optional (default=1e-6)\n",
    "            ``abs_corr_mat`` can have nans, which will be replaced\n",
    "            with ``tolerance``.\n",
    "        Returns\n",
    "        -------\n",
    "        abs_corr_mat : ndarray, shape (n_features, n_features)\n",
    "            Absolute correlation matrix of ``X`` at the beginning of the\n",
    "            current round. The diagonal has been zeroed out and each feature's\n",
    "            absolute correlations with all others have been normalized to sum\n",
    "            to 1.\n",
    "        \"\"\"\n",
    "        n_features = X_filled.shape[1]\n",
    "        if (self.n_nearest_features is None or\n",
    "                self.n_nearest_features >= n_features):\n",
    "            return None\n",
    "        abs_corr_mat = np.abs(np.corrcoef(X_filled.T))\n",
    "        # np.corrcoef is not defined for features with zero std\n",
    "        abs_corr_mat[np.isnan(abs_corr_mat)] = tolerance\n",
    "        # ensures exploration, i.e. at least some probability of sampling\n",
    "        abs_corr_mat[abs_corr_mat < tolerance] = tolerance\n",
    "        # features are not their own neighbors\n",
    "        np.fill_diagonal(abs_corr_mat, 0)\n",
    "        # needs to sum to 1 for np.random.choice sampling\n",
    "        abs_corr_mat = normalize(abs_corr_mat, norm='l1', axis=0, copy=False)\n",
    "        return abs_corr_mat\n",
    "\n",
    "    def _initial_imputation(self, X):\n",
    "        \"\"\"Perform initial imputation for input X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            Input data, where \"n_samples\" is the number of samples and\n",
    "            \"n_features\" is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        Xt : ndarray, shape (n_samples, n_features)\n",
    "            Input data, where \"n_samples\" is the number of samples and\n",
    "            \"n_features\" is the number of features.\n",
    "        X_filled : ndarray, shape (n_samples, n_features)\n",
    "            Input data with the most recent imputations.\n",
    "        mask_missing_values : ndarray, shape (n_samples, n_features)\n",
    "            Input data's missing indicator matrix, where \"n_samples\" is the\n",
    "            number of samples and \"n_features\" is the number of features.\n",
    "        \"\"\"\n",
    "        X = check_array(X, dtype=FLOAT_DTYPES, order=\"F\",\n",
    "                        force_all_finite=False\n",
    "                        if self.missing_values == 'NaN'\n",
    "                        or np.isnan(self.missing_values) else True)\n",
    "\n",
    "        mask_missing_values = _get_mask(X, self.missing_values)\n",
    "        if self.initial_imputer_ is None:\n",
    "            self.initial_imputer_ = SimpleImputer(\n",
    "                                            missing_values=self.missing_values,\n",
    "                                            strategy=self.initial_strategy)\n",
    "            X_filled = self.initial_imputer_.fit_transform(X)\n",
    "        else:\n",
    "            X_filled = self.initial_imputer_.transform(X)\n",
    "\n",
    "        valid_mask = np.flatnonzero(np.logical_not(\n",
    "            np.isnan(self.initial_imputer_.statistics_)))\n",
    "        Xt = X[:, valid_mask]\n",
    "        mask_missing_values = mask_missing_values[:, valid_mask]\n",
    "\n",
    "        return Xt, X_filled, mask_missing_values\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"Fits the imputer on X and return the transformed X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Input data, where \"n_samples\" is the number of samples and\n",
    "            \"n_features\" is the number of features.\n",
    "        y : ignored.\n",
    "        Returns\n",
    "        -------\n",
    "        Xt : array-like, shape (n_samples, n_features)\n",
    "             The imputed input data.\n",
    "        \"\"\"\n",
    "        self.random_state_ = getattr(self, \"random_state_\",\n",
    "                                     check_random_state(self.random_state))\n",
    "\n",
    "        if self.predictor is None:\n",
    "            from sklearn.linear_model import BayesianRidge\n",
    "            self._predictor = BayesianRidge()\n",
    "        else:\n",
    "            self._predictor = clone(self.predictor)\n",
    "\n",
    "        self._min_value = np.nan if self.min_value is None else self.min_value\n",
    "        self._max_value = np.nan if self.max_value is None else self.max_value\n",
    "\n",
    "        self.initial_imputer_ = None\n",
    "        X, X_filled, mask_missing_values = self._initial_imputation(X)\n",
    "\n",
    "        # edge case: in case the user specifies 0 for n_imputations,\n",
    "        # then there is no need to do burn in and the result should be\n",
    "        # just the initial imputation (before clipping)\n",
    "        if self.n_imputations < 1:\n",
    "            return X_filled\n",
    "\n",
    "        X_filled = np.clip(X_filled, self._min_value, self._max_value)\n",
    "\n",
    "        # order in which to impute\n",
    "        # note this is probably too slow for large feature data (d > 100000)\n",
    "        # and a better way would be good.\n",
    "        # see: https://goo.gl/KyCNwj and subsequent comments\n",
    "        ordered_idx = self._get_ordered_idx(mask_missing_values)\n",
    "\n",
    "        abs_corr_mat = self._get_abs_corr_mat(X_filled)\n",
    "\n",
    "        # impute data\n",
    "        n_rounds = self.n_burn_in + self.n_imputations\n",
    "        n_samples, n_features = X_filled.shape\n",
    "        Xt = np.zeros((n_samples, n_features), dtype=X.dtype)\n",
    "        self.imputation_sequence_ = []\n",
    "        if self.verbose > 0:\n",
    "            print(\"[MICE] Completing matrix with shape %s\" % (X.shape,))\n",
    "        start_t = time()\n",
    "        for i_rnd in range(n_rounds):\n",
    "            if self.imputation_order == 'random':\n",
    "                ordered_idx = self._get_ordered_idx(mask_missing_values)\n",
    "\n",
    "            for feat_idx in ordered_idx:\n",
    "                neighbor_feat_idx = self._get_neighbor_feat_idx(n_features,\n",
    "                                                                feat_idx,\n",
    "                                                                abs_corr_mat)\n",
    "                X_filled, predictor = self._impute_one_feature(\n",
    "                    X_filled, mask_missing_values, feat_idx, neighbor_feat_idx,\n",
    "                    predictor=None, fit_mode=True)\n",
    "                predictor_triplet = MICETriplet(feat_idx,\n",
    "                                                neighbor_feat_idx,\n",
    "                                                predictor)\n",
    "                self.imputation_sequence_.append(predictor_triplet)\n",
    "\n",
    "            if i_rnd >= self.n_burn_in:\n",
    "                Xt += X_filled\n",
    "            if self.verbose > 0:\n",
    "                print('[MICE] Ending imputation round '\n",
    "                      '%d/%d, elapsed time %0.2f'\n",
    "                      % (i_rnd + 1, n_rounds, time() - start_t))\n",
    "\n",
    "        Xt /= self.n_imputations\n",
    "        Xt[~mask_missing_values] = X[~mask_missing_values]\n",
    "        return Xt\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Imputes all missing values in X.\n",
    "        Note that this is stochastic, and that if random_state is not fixed,\n",
    "        repeated calls, or permuted input, will yield different results.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The input data to complete.\n",
    "        Returns\n",
    "        -------\n",
    "        Xt : array-like, shape (n_samples, n_features)\n",
    "             The imputed input data.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'initial_imputer_')\n",
    "\n",
    "        X, X_filled, mask_missing_values = self._initial_imputation(X)\n",
    "\n",
    "        # edge case: in case the user specifies 0 for n_imputations,\n",
    "        # then there is no need to do burn in and the result should be\n",
    "        # just the initial imputation (before clipping)\n",
    "        if self.n_imputations < 1:\n",
    "            return X_filled\n",
    "\n",
    "        X_filled = np.clip(X_filled, self._min_value, self._max_value)\n",
    "\n",
    "        n_rounds = self.n_burn_in + self.n_imputations\n",
    "        n_imputations = len(self.imputation_sequence_)\n",
    "        imputations_per_round = n_imputations // n_rounds\n",
    "        i_rnd = 0\n",
    "        Xt = np.zeros(X.shape, dtype=X.dtype)\n",
    "        if self.verbose > 0:\n",
    "            print(\"[MICE] Completing matrix with shape %s\" % (X.shape,))\n",
    "        start_t = time()\n",
    "        for it, predictor_triplet in enumerate(self.imputation_sequence_):\n",
    "            X_filled, _ = self._impute_one_feature(\n",
    "                X_filled,\n",
    "                mask_missing_values,\n",
    "                predictor_triplet.feat_idx,\n",
    "                predictor_triplet.neighbor_feat_idx,\n",
    "                predictor=predictor_triplet.predictor,\n",
    "                fit_mode=False\n",
    "            )\n",
    "            if not (it + 1) % imputations_per_round:\n",
    "                if i_rnd >= self.n_burn_in:\n",
    "                    Xt += X_filled\n",
    "                if self.verbose > 1:\n",
    "                    print('[MICE] Ending imputation round '\n",
    "                          '%d/%d, elapsed time %0.2f'\n",
    "                          % (i_rnd + 1, n_rounds, time() - start_t))\n",
    "                i_rnd += 1\n",
    "\n",
    "        Xt /= self.n_imputations\n",
    "        Xt[~mask_missing_values] = X[~mask_missing_values]\n",
    "        return Xt\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fits the imputer on X and return self.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Input data, where \"n_samples\" is the number of samples and\n",
    "            \"n_features\" is the number of features.\n",
    "        y : ignored\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        self.fit_transform(X)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer()\n",
    "imp.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imp = imp.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.46666667e+00,  -1.18018811e-01,   6.06196848e-01, ...,\n",
       "         -1.37425710e-04,  -9.32755090e-06,   1.34078046e-04],\n",
       "       [  4.46666667e+00,  -1.18018811e-01,   6.06196848e-01, ...,\n",
       "         -1.24991766e-04,  -6.91237354e-06,   2.55810798e-04],\n",
       "       [  4.46666667e+00,  -6.96726938e-01,   7.39590680e-01, ...,\n",
       "         -6.65597282e-04,  -2.70453260e-04,  -3.71882881e-04],\n",
       "       ..., \n",
       "       [  4.46666667e+00,  -1.71889816e-01,   1.19495228e+00, ...,\n",
       "          2.20964847e-03,  -9.00679551e-04,   4.39911954e-04],\n",
       "       [  4.46666667e+00,  -6.54821085e-02,  -9.29163634e-01, ...,\n",
       "          1.93903032e-03,   3.28955141e-03,   1.18553165e-03],\n",
       "       [  4.46666667e+00,  -1.39551552e+00,   9.95167222e-01, ...,\n",
       "          4.87304324e-04,  -1.83804637e-04,  -1.86843797e-04]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Dimensionality Reduction\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 122).fit(X_imp)\n",
    "X_pca = pca.transform(X_imp)\n",
    "\n",
    "# for i in range(1,180) :\n",
    "#     pca = PCA(n_components = i)\n",
    "#     pca.fit(X_imp)\n",
    "#     score, clif= train(i)\n",
    "#     if score > score_max:\n",
    "#         score_max = score\n",
    "#         clf_max = claf\n",
    "# best = clf_max.fit(X_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 122)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=3, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def outliers_modified_z_score(ys):\n",
    "    threshold = 3.5\n",
    "\n",
    "    median_y = np.median(ys)\n",
    "    median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in ys])\n",
    "    modified_z_scores = [0.6745 * (y - median_y) / median_absolute_deviation_y\n",
    "                         for y in ys]\n",
    "    return np.where(np.abs(modified_z_scores) > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def outliers_z_score(ys):\n",
    "    threshold = 3\n",
    "\n",
    "    mean_y = np.mean(ys)\n",
    "    stdev_y = np.std(ys)\n",
    "    z_scores = [(y - mean_y) / stdev_y for y in ys]\n",
    "    return np.where(np.abs(z_scores) > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),)\n",
      "(array([  0,  15, 185, 241, 252, 255, 349, 354]),)\n",
      "(array([274, 325]),)\n",
      "(array([], dtype=int64),)\n",
      "(array([202]),)\n",
      "(array([], dtype=int64),)\n",
      "(array([ 79, 150, 265, 283, 300, 355]),)\n",
      "(array([  4,  26,  38,  71, 150, 202, 210, 263, 272, 297, 356]),)\n",
      "(array([  4,  22, 282, 300]),)\n",
      "(array([  4, 111, 189, 312, 353]),)\n",
      "(array([  4,  22,  61, 103, 144, 200, 385]),)\n",
      "(array([  4,  22,  61, 103, 144, 165, 210, 233, 245, 272, 297, 385]),)\n",
      "(array([ 98, 198, 235, 241, 283]),)\n",
      "(array([  4,  61, 121, 282, 300, 366]),)\n",
      "(array([  4,  22,  61, 131, 150, 156, 180, 200, 210, 244, 246, 281, 324,\n",
      "       353, 381]),)\n",
      "(array([ 19,  25,  88, 106, 114, 178, 201, 212, 263, 356]),)\n",
      "(array([116, 187, 272, 391]),)\n",
      "(array([272, 283, 354, 363, 384]),)\n",
      "(array([200, 272]),)\n",
      "(array([], dtype=int64),)\n",
      "(array([200, 283]),)\n",
      "(array([215, 278]),)\n",
      "(array([101, 220, 225, 276, 282, 336, 350, 388, 389]),)\n",
      "(array([], dtype=int64),)\n",
      "(array([ 27,  38,  92, 107, 137, 369]),)\n",
      "(array([ 80,  92, 107, 126, 369, 379]),)\n",
      "(array([ 23,  27,  53,  80,  92, 107, 126, 162, 379]),)\n",
      "(array([ 27,  53,  92, 107, 126]),)\n",
      "(array([ 27,  69,  80,  92, 107, 398]),)\n",
      "(array([ 27,  59,  69, 111, 126, 173, 289, 336, 379, 398]),)\n",
      "(array([ 23,  53,  69, 103, 107, 126, 162, 180, 260, 289, 336, 369]),)\n",
      "(array([ 80, 103, 111, 162, 173, 336, 398]),)\n",
      "(array([ 69,  80, 103, 162, 173, 194, 289, 322, 336, 369, 398]),)\n",
      "(array([ 23,  27,  80,  92, 162, 173, 184, 194]),)\n",
      "(array([ 80, 103, 184, 289, 336, 379, 398]),)\n",
      "(array([ 23,  59,  69, 162, 173, 261, 346, 348, 379]),)\n",
      "(array([ 23,  69,  80, 103, 173, 194, 260, 268, 322, 336, 379, 398]),)\n",
      "(array([ 69, 114, 184, 210, 322, 369]),)\n",
      "(array([ 23,  38,  59,  92, 109, 126, 150, 180, 215, 336]),)\n",
      "(array([ 23,  53,  96, 111, 162, 194, 261, 343, 369, 379]),)\n",
      "(array([ 53,  80, 104, 126, 139, 173, 180, 266, 268]),)\n",
      "(array([ 23,  27,  38,  59,  69, 111, 173, 289, 369]),)\n",
      "(array([  9,  53, 104, 139, 173, 194, 201, 243, 315, 369]),)\n",
      "(array([  9, 152, 168, 180, 201, 218, 260, 266, 322, 348, 349]),)\n",
      "(array([150, 184, 268]),)\n",
      "(array([111, 173, 180, 184, 194, 210, 348]),)\n",
      "(array([ 11,  38,  63, 229, 268, 289, 343, 346, 353, 371, 376, 379]),)\n",
      "(array([ 11, 139, 141, 218, 288, 343, 349, 369, 371]),)\n",
      "(array([  9,  59, 195, 288, 289, 343, 386]),)\n",
      "(array([ 59, 103, 111, 150, 183, 324, 343]),)\n",
      "(array([ 38, 111, 162, 201, 215, 236, 268, 310, 315, 322, 349]),)\n",
      "(array([ 74, 104, 139, 266, 284, 312, 323, 346, 371]),)\n",
      "(array([ 11,  63, 103, 180, 183, 215, 268, 296, 301, 315, 384]),)\n",
      "(array([ 53,  63, 139, 180, 270, 290, 300, 312, 343, 379]),)\n",
      "(array([ 96, 111, 114, 261, 284, 289, 301]),)\n",
      "(array([ 11, 104, 201, 244, 270, 284, 322, 349, 381]),)\n",
      "(array([ 57,  63, 168, 268, 322, 394]),)\n",
      "(array([  0,  36, 137, 210, 343, 346]),)\n",
      "(array([ 63, 114, 141, 150, 163, 301, 381]),)\n",
      "(array([  9, 296, 309]),)\n",
      "(array([  9, 126, 184, 215, 239, 296]),)\n",
      "(array([ 59, 184, 195, 259, 290, 381]),)\n",
      "(array([104, 148, 165, 343, 346, 348]),)\n",
      "(array([ 38,  63, 126, 141, 201, 239, 386]),)\n",
      "(array([ 63, 290, 377]),)\n",
      "(array([ 16,  21, 259, 261, 315]),)\n",
      "(array([114, 152, 172, 195, 250]),)\n",
      "(array([ 28, 172, 215, 343]),)\n",
      "(array([141, 266, 299, 306]),)\n",
      "(array([ 51, 183, 266, 290, 371]),)\n",
      "(array([122, 123, 301, 335, 371, 384]),)\n",
      "(array([ 37,  63,  74, 180, 260, 322]),)\n",
      "(array([  0, 109, 150, 166, 183, 259]),)\n",
      "(array([147, 268, 349]),)\n",
      "(array([ 10,  60, 129, 166, 180]),)\n",
      "(array([ 57, 109, 148, 204, 303, 323, 397]),)\n",
      "(array([ 57, 114]),)\n",
      "(array([  9,  16,  35, 270, 312, 324]),)\n",
      "(array([114, 223, 288, 346]),)\n",
      "(array([ 20,  93, 147, 218]),)\n",
      "(array([  5,  57, 218, 381]),)\n",
      "(array([ 16,  20,  57, 135, 215, 266]),)\n",
      "(array([ 90, 150]),)\n",
      "(array([ 51, 218, 300]),)\n",
      "(array([ 10, 123, 279, 301]),)\n",
      "(array([109, 306, 328, 382]),)\n",
      "(array([109, 163, 207, 218, 318]),)\n",
      "(array([152]),)\n",
      "(array([243, 310, 315]),)\n",
      "(array([ 51, 148, 233, 385]),)\n",
      "(array([213, 371]),)\n",
      "(array([ 74, 246, 324, 382]),)\n",
      "(array([5]),)\n",
      "(array([259]),)\n",
      "(array([ 68,  88, 163, 311]),)\n",
      "(array([134, 182, 296, 346]),)\n",
      "(array([ 68, 131]),)\n",
      "(array([ 93, 244, 397]),)\n",
      "(array([ 13, 138, 249, 341, 345]),)\n",
      "(array([ 93, 124, 166, 215, 246]),)\n",
      "(array([301]),)\n",
      "(array([ 51, 138, 321]),)\n",
      "(array([248, 270, 387]),)\n",
      "(array([178, 395]),)\n",
      "(array([168, 202, 288]),)\n",
      "(array([205]),)\n",
      "(array([205, 384]),)\n",
      "(array([ 96, 166, 217, 341]),)\n",
      "(array([], dtype=int64),)\n",
      "(array([217, 291]),)\n",
      "(array([16]),)\n",
      "(array([], dtype=int64),)\n",
      "(array([302, 392]),)\n",
      "(array([148, 341]),)\n",
      "(array([  0, 327]),)\n",
      "(array([118, 166, 324]),)\n",
      "(array([271, 279, 321]),)\n",
      "(array([], dtype=int64),)\n",
      "(array([ 36,  97, 305]),)\n",
      "(array([124, 286]),)\n",
      "(array([105, 202, 324]),)\n",
      "(array([118, 178]),)\n"
     ]
    }
   ],
   "source": [
    "for i in range(122):\n",
    "    X_outliers = outliers_z_score(X_pca[:,i])\n",
    "    print X_outliers\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
